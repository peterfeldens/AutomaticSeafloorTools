{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here, we want to take the outpout bounding boxes of the stone detection program for a set of validation\n",
    "tifs, and check whether manually determined picks are located within the bounding boxes\n",
    "\n",
    "The result is to be plotted as a onfusion matri for each of the alidation mosaics.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from descartes import PolygonPatch\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon\n",
    "import os\n",
    "\n",
    "\n",
    "args.model\n",
    "args.minside\n",
    "\n",
    "validation_areas = ['tif1',   # TIF in PTG\n",
    "                    'tif2'         #TIF somewhere else\n",
    "                    ]\n",
    "\n",
    "reference_picks = 0   #best: same name as tif with different ending, like .picks\n",
    "]\n",
    "\n",
    "for area in validation_areas:\n",
    "    reference  = area.split('.tif') + \".shp\"\n",
    "# run the neural networks over the validation areas\n",
    "    if run_network==1:\n",
    "        resultfile_model = area.split('.tif') + \"_modelresult.csv\n",
    "        cmd = \"python appy_object_decetion.py \" + area + \" \" args.model  + \" \" + resultfile_model + \"  --detection_threshold=0.2 --minside=\" + args.minside\n",
    "        os.system(command)\n",
    "\n",
    "# Load the result.csv file from the neural network\n",
    "    point = geopandas.GeoDataFrame.from_file(reference)\n",
    "    df_model = pd.read_csv(resultfile_model)\n",
    "    df_model['Coordinates'] = df_model['WKT_GEOMETRY'].apply(wkt.loads)\n",
    "    poly = geopandas.GeoDataFrame(df_model, geometry='Coordinates')\n",
    "\n",
    "\n",
    "    correct_stones = pointInPolys.groupby('index_right')\n",
    "\n",
    "    pointNotInPolys = point.loc[point.disjoint(poly.unary_union)]  # how=\"outer\" is not implemented in geopandas?\n",
    "    list(grouped)\n",
    "\n",
    "\n",
    "    #accout for potential multi-detections\n",
    "\n",
    "    #Calculate confusion matric\n",
    "    number_of_entries = len(point)\n",
    "    true_positive = len(correct_stones)\n",
    "    false_positive = len(pointNotInPolys)\n",
    "    false_negative = len(pointNotInPolys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "   from geopandas.tools import sjoin\n",
    "   import pandas as pd\n",
    "   from descartes import PolygonPatch\n",
    "   from shapely.geometry import Point, Polygon, MultiPolygon\n",
    "   import os\n",
    "   from shapely import wkt\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%import geopandas as gpd\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5714285714285714 0.32 0.41025641025641024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peter/anaconda/anaconda3/envs/geo/lib/python3.6/site-packages/geopandas/geodataframe.py:422: RuntimeWarning: Sequential read of iterator was interrupted. Resetting iterator. This can negatively impact the performance.\n",
      "  for feature in features_lst:\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely import wkt\n",
    "from geopandas.tools import sjoin\n",
    "\n",
    "ref_shape = \"./../temp/val_01_utm32nwgs84.shp\"\n",
    "ref_point = gpd.GeoDataFrame.from_file(ref_shape)\n",
    "\n",
    "model_csv = \"./../temp/val_01_utm32nwgs84.csv\"\n",
    "model_poly = gpd.GeoDataFrame.from_file(model_csv)\n",
    "\n",
    "# TP und FN\n",
    "pointInPolys = sjoin(ref_point, model_poly, how='left')\n",
    "notfound_stones = pointInPolys[pointInPolys['index_right'].isnull()]\n",
    "found_stones = pointInPolys[pointInPolys['index_right'].notnull()]\n",
    "duplicate_detections = found_stones[found_stones.duplicated(['index_right'])]\n",
    "\n",
    "#FP: Polygon outside points\n",
    "polys_with_points = found_stones['index_right'].unique()\n",
    "polys_without_points = model_poly[~model_poly.index.isin(polys_with_points)]\n",
    "\n",
    "\n",
    "# Calculate and print confusion matrix\n",
    "true_number = len(ref_point)\n",
    "detected_number = len(model_poly)\n",
    "tp = len(found_stones) - len(duplicate_detections)\n",
    "fn = len(notfound_stones)\n",
    "#fp = bounding boxes without point\n",
    "fp = len(polys_without_points)\n",
    "\n",
    "precision = tp / (tp+fp)\n",
    "recall = tp / (tp+fn)\n",
    "F1 = 2*tp / ( 2*tp + fp + fn)\n",
    "\n",
    "print(precision, recall, F1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}